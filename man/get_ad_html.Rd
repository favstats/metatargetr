% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_ad_html.R
\name{get_ad_html}
\alias{get_ad_html}
\title{Fetch Facebook Ad-Library pages (with caching)}
\usage{
get_ad_html(
  ad_ids,
  country,
  cache_dir = NULL,
  overwrite = FALSE,
  strip_css = TRUE,
  wait_sec = 3,
  log_failed_ids = NULL,
  quiet = FALSE,
  return_type = c("paths", "list")
)
}
\arguments{
\item{ad_ids}{Character vector of Ad-Library IDs.}

\item{country}{Two-letter country code.}

\item{cache_dir}{Directory where \emph{.html.gz} files will be stored.
Defaults to the value set during interactive setup,
or "html_cache".}

\item{overwrite}{If FALSE (default) keep already-cached files.}

\item{strip_css}{Run fast regex-based CSS removal on downloaded pages.}

\item{wait_sec}{Seconds to wait for each page to load (default 3).}

\item{log_failed_ids}{If a character path is provided (e.g., "log.txt"),
failed IDs will be appended to that file.}

\item{quiet}{Suppress progress messages.}

\item{return_type}{\code{"paths"} (default) or \code{"list"} for in-memory strings.}
}
\value{
Either a named character vector of file paths or a named list of
HTML strings, in the \emph{same order} as \code{ad_ids}.
}
\description{
Retrieves HTML content for Facebook Ad Library pages using headless Chrome
to bypass JavaScript-based bot detection. Results are cached to disk.
}
